install.packages('swirl')
package_version('swirl')
install.packages('swirl')
packageVersion('swirl')
install_from_swirl("Exploratory Data Analysis")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
swirl()
dist(dataFrame)
hc <- hclust(distxy)
plot(hc)
plot(as.dendrogram(hc))
abline(h=1.5, col='blue')
abline(h=.4, col='red')
5
12
abline(h=.05, col='green')
dist(dFsm)
hc
heatmap(dataMatrix, col=cm.colors(25))
heatmap(mt)
mt
plot(denmt)
distmt
cmat
points(cx, cy, col=c('red', 'orange', 'purple'), pch=3, cex=2, lwd=2)
mdist(x, y, cx, cy)
apply(distTemp, 2, which.min())
apply(distTemp, 2, which.min)
apply(distTmp, 2, which.min)
points(x, y, pch=19, cex=2, col=cols1[newClust])
tapply(x, newClust, mean)
tapply(y, newClust, mean)
points(newCx, newCy, col=cols1, pch=8, cex=2, lwd=2)
mdist(x, y, newCx, newCy)
apply(distTmp2, 2, which.min)
recolor(x, y, pch=19, cex=2, col=cols1[newClust2])
points(x, y, pch=19, cex=2, col=cols1[newClust2])
tapply(x, newClust2, mean)
tapply(y, newClust2, mean)
points(finalCx, finalCy, col=cols1, pch=9, cex=2, lwd=2)
kmeans(dataFrame, centers = 3)
kmObj$iter
plot(x, y, col=mkObj$cluster, pch=19, cex=2)
plot(x, y, col=kmObj$cluster, pch=19, cex=2)
plot(kmObj$centers, kmObj$centers, col=c('black', 'red', 'green'), pch=3, cex=3, lwd=3)
plot(kmObj$centers, col=c('black', 'red', 'green'), pch=3, cex=3, lwd=3)
points(kmObj$centers, col=c('black', 'red', 'green'), pch=3, cex=3, lwd=3)
plot(x, y, col=kmeans(dataFrame,6)$cluster, pch=19, cex=2)
plot(x, y, col=kmeans(dataFrame,6)$cluster, pch=19, cex=2)
plot(x, y, col=kmeans(dataFrame,6)$cluster, pch=19, cex=2)
head(dataMatrix)
heatmap(dataMatrix)
myedit('addPatt.R')
source('addPatt.R', local=TRUE)
heatmap(dataMatrix)
mat
svd(mat)
matu %*% diag %*% t(matv)
svd(scale(mat))
prcomp(scale(mat))
svd$v[,1]
svd1$v[,1]
svd1$d
head(constantMatrix)
svd2$d
svd2
svd2$v[,1:2]
svd2$d
dim(faceData)
a1 <- (svd1$u * svd1$d) %*% svd1$v
a1 <- (svd1$u[,1] * svd1$d[1]) %*% svd1$v[,1]
a1 <- (svd1$u[,1] * svd1$d[1]) %*% t(svd1$v[,1])
myimage(a1)
myImage(a1)
a2 <- svd1$u[,1:2] %*% svd1$d[1:2] %*% t(svd1$v[,1:2])
a2 <- svd1$u[,1:2] %*% diag(svd1$d[1:2]) %*% t(svd1$v[,1:2])
myImage(a2)
a2 <- svd1$u[,1:5] %*% diag(svd1$d[1:5]) %*% t(svd1$v[,1:5])
myImage(svd1$u[,1:5] %*% diag(svd1$d[1:5]) %*% t(svd1$v[,1:5]))
myImage(svd1$u[,1:10] %*% diag(svd1$d[1:10]) %*% t(svd1$v[,1:10]))
dim(ssd)
names(ssd[,562:563])
table(ssd$subject)
sum(table(ssd$subject))
table(ssd$activity)
sub1 <- subset(ssd, subject=1)
sub1 <- subset(ssd, subject==1)
sub1
dim(sub1)
names(sub1[,1:12])
myedit('showXY.R')
showMe(1:6)
mdist <- dist(sub1[,1:3])
hclustering <- hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
mdist <- dist(sub1[,10:12])
hclustering <- hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
svd1 <- svd(scale(sub1[,-c(562, 563)]))
svd1$u
dim(svd1$u)
maxCon <- which.max(svd1$v[,2])
mdist <- dist(sub1[,c(10:12, maxCon)])
hclustering <- hclust(mdist)
myplclust(hclustering, lab.col=unclass(sub1$activity))
names(sub1[maxCon])
kClust <- kmeans(sub1[,-c(562, 563), set=6])
kClust <- kmeans(sub1[,-c(562, 563)], set=6)
kClust <- kmeans(sub1[,-c(562, 563)], centers=6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[,-c(562, 563)], centers=6, nstart = 100)
table(kClust$cluster, sub1$activity)
dim(kClust$centers)
laying <- which(kClust$size==29)
plot(kClust$centers[laying, 1:12], pch=19, ylab='Laying Cluster')
names(sub1[,1:3])
walkdown <- which(kClust$size==49)
plot(kClust$centers[walkdown,1:12], pch=19, ylab = 'Walkdown Cluster')
install.packages('caret')
install.packages('AppliedPredictiveModeling')
install.packages('ElemStatLearn')
install.packages('pgmm')
install.packages('rpart')
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
?rpart
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
train <- segmentationOriginal[inTrain]
test <- segmentationOriginal[-inTrain]
model <- rpart(Case ~ ., data=train)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
train <- segmentationOriginal[inTrain]
test <- segmentationOriginal[-inTrain]
model <- rpart(Case ~ ., data=train)
library(rpart)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
train <- segmentationOriginal[inTrain]
test <- segmentationOriginal[-inTrain]
model <- rpart(Case ~ ., data=train)
train
segmentationOriginal
inTrain
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
train <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
train
model <- rpart(Case ~ ., data=train)
d1 <- data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2)
d1 <- data.frame([23000, 10, 2], colnames(['TotalIntench2','FiberWidthCh1','PerimStatusCh1']))
d1 <- data.frame(c(23000, 10, 2), colnames(c('TotalIntench2','FiberWidthCh1','PerimStatusCh1'))
p1 <- predict(model, d1)
d1 <- data.frame(c(23000, 10, 2), colnames=c('TotalIntench2','FiberWidthCh1','PerimStatusCh1')
p1 <- predict(model, d1)
d1 <- data.frame(data=c(23000, 10, 2), colnames=c('TotalIntench2','FiberWidthCh1','PerimStatusCh1')
p1 <- predict(model, d1)
?data.frame
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
train <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
model <- rpart(Case ~ ., data=train)
d1 <- data.frame(data=c(23000, 10, 2), colnames=c('TotalIntench2','FiberWidthCh1','PerimStatusCh1')
p1 <- predict(model, d1)
library(rpart)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
train <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
model <- rpart(Case ~ ., data=train)
d1 <- data.frame(data=c(23000, 10, 2), colnames=c('TotalIntench2','FiberWidthCh1','PerimStatusCh1')
p1 <- predict(model, d1)
model$finalModel
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
train <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
model <- rpart(Case ~ ., data=train)
model$finalModel
model <- train(Class ~ ., method = "rpart", data = training)
model <- train(Class ~ ., method = "rpart", data = train)
model$finalModel
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
set.seed(125)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
train <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
model <- train(Class ~ ., method = "rpart", data = train)
model$finalModel
install.packages('e1071')
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
set.seed(125)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=.6, list=FALSE)
train <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
model <- train(Class ~ ., method = "rpart", data = train)
model$finalModel
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
install.packages('rpart.plot')
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
install.packages('rattle')
library(rpart.plot)
library(rattle)
fancyRpartPlot(model$finalModel)
install.packages('rattle')
library(rattle)
suppressMessages(library(rattle))
install.packages('rattle')
install.packages('RGtk2')
install.packages('RGtk2')
library(pgmm)
data(olive)
olive = olive[,-1]
model <- train(Area ~ ., method='rpart', data=olive)
?predict
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata = newdata)
olive.head()
head(olive)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass = function(values, prediction){sum(((prediction > 0.5) * 1) != values) / length(values)}
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = testSA))
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
missClass(testSA$chd, predict(modelSA, newdata = testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
?randomForest
library(randomForest)
install.packages('randomForest')
library(randomForest)
library(ElemStatLearn)
library(randomForest)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(gbm)
library(lubridate)
library(forecast)
library(e1071)
install.packages('gbm')
install.packages('lubridate')
install.packages('forecast')
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(gbm)
library(lubridate)
library(forecast)
library(e1071)
install.packages('forecast', dependencies = TRUE)
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(gbm)
library(lubridate)
library(forecast)
library(e1071)
install.packages('TTR')
install.packages('TTR', dependencies = TRUE)
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(gbm)
library(lubridate)
library(forecast)
library(e1071)
data(vowel.train)
data(vowel.test)
y <- c(as.factor(vowel.train), as.factor(vowel.test))
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
?train
names(getModelInfo())
model1 <- train(y ~ ., method='rf', data=vowel.train)
model2 <- train(y ~ ., method='gbm', data=vowel.train)
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
pred_rf <- predict(model1, vowel.test)
pred_gbm <- predict(model2, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
set.seed(33833)
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
head(training)
rf <- train(diagnosis ~ ., method='rf', data=train)
rf <- train(diagnosis ~ ., method='rf', data=training)
rf_model <- train(diagnosis ~ ., method='rf', data=training)
gbm_model <- train(diagnosis ~ ., method='gbm', data=training)
lda_model <- train(diagnosis ~ ., method='lda', data=training)
pred_rf <- predict(rf_model, testing)
pred_gbm <- predict(gbm_model, testing)
pred_lda <- predict(lda_model, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
set.seed(3523)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso <- train(Compressive Strength ~ ., method='lasso', data=concrete)
head(concrete)
lasso <- train(CompressiveStrength ~ ., method='lasso', data=concrete)
?plot.enet
library(lars)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
plot.enet(lasso$finalModel, xvar = "penalty", use.color = TRUE)
set.seed(3523)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(3523)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
confusionMatrix(pred_svm, testing$CompressiveStrength)
confusionMatrix(pred_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
library(e1071)
accuracy(pred_svm, testing$CompressiveStrength)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
setwd("/Users/christel/desktop/coursera week8")
library(caret)
train_data <- read.csv('pml-training.csv')
test_data <- read.csv('pml-testing.csv')
set.seed(122334444)
part <- createDataPartition(y=train_data$classe, p=0.7, list=FALSE)
train <- train_data[part,]
validation <- train_data[-part,]
NZV <- nearZeroVar(train)
train <- train[, -NZV]
validation  <- validation[, -NZV]
AllNA    <- sapply(train, function(x) mean(is.na(x))) > 0.95
train <- train[, AllNA==FALSE]
validation  <- validation[, AllNA==FALSE]
model1 <- train(classe ~., data=train, method='rf', number=5)
library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
install.packages(rattle)
install.packages('rattle')
install.packages('corrplot')
library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
install.packages('rattle')
install.packages('rattle')
library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
#library(rattle)
library(randomForest)
library(corrplot)
model1 <- train(classe ~., data=train, method='rf', number=5)
model1$finalModel
predict_rf <- predict(model1, newdata=validation)
conf <- confusionMatrix(predict_rf, validation$classe)
conf
library(parallel)
library(doParallel)
install.packages('doParallel')
## make this go faster ##
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
model2 <- train(classe ~., data=train, method='svm', number=5)
stopCluster(cl)
library(doParallel)
## make this go faster ##
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
model2 <- train(classe ~., data=train, method='svm', number=5)
stopCluster(cl)
## make this go faster ##
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
model2 <- train(classe ~., data=train, method="svmLinear", number=5)
## make this go faster ##
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
model2 <- train(classe ~., data=train, method="svmLinear", number=5)
stopCluster(cl)
predict_svm <- predict(model2, newdata=validation)
conf <- confusionMatrix(predict_svm, validation$classe)
conf
predict_test <- predict(model2, newdata=test_data)
predict_test
predict_test <- predict(model1, newdata=test_data)
predict_test
train_data <- read.csv('pml-training.csv')
test_data <- read.csv('pml-testing.csv')
predict_test <- predict(model1, newdata=test_data)
predict_test
test_data
